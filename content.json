{"meta":{"title":"小飞侠","subtitle":null,"description":null,"author":"kevin","url":"http://kevingeek.github.io","root":"/"},"pages":[],"posts":[{"title":"Java常用诊断工具","slug":"Java常用诊断工具","date":"2020-04-15T19:14:10.000Z","updated":"2020-04-15T19:14:10.128Z","comments":true,"path":"2020/04/16/Java常用诊断工具/","link":"","permalink":"http://kevingeek.github.io/2020/04/16/Java%E5%B8%B8%E7%94%A8%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/","excerpt":"额，咋说呢，好记性不如烂笔头，可以把一些东西给串起来，","text":"额，咋说呢，好记性不如烂笔头，可以把一些东西给串起来， Java相关命令常用的命令： jstack通常来说，如果出现程序卡死了（比如restart tomcat的时候），不知道卡哪儿了，咋办呢，用jstack看一下哪个线程在干事 jstack -l $(pid) jstat这个貌似就是用来看gc的。。平时一般其他的也都用不上啊 jstat [-命令选项] [vmid] [间隔时间/毫秒] [查询次数] jmap基本上，用到了jmap就是内存泄漏了常用命令 jmap -histo $(pid) jcmd 发送诊断命令，似乎啥都能干，发送help命令，可以基本看一些能干的事 jcmd $(pid) help jmcjmc其实就有点意思，说白了是一个特性，配合和jfr使用， 系统相关的命令free看内存的常用命令，看一下总内存、已用内存、空闲内存、共享内存、buff/cache内存和可用内存的大小以及swap分区的大小（可以看到，我的机器上swap分区大小为0，就是说不会产生swap，直接OOM，避免产生swap机制带来的IO瓶颈问题） [kevin@ky1 ~]$ free -h total used free shared buff/cache available Mem: 3.7Gi 823Mi 360Mi 0.0Ki 2.5Gi 2.6Gi Swap: 0B 0B 0B toptop命令，集大成，不展开说了 [kevin@ky1 ~]$ top top - 23:16:12 up 12 days, 4:16, 1 user, load average: 0.13, 0.04, 0.01 Tasks: 105 total, 1 running, 104 sleeping, 0 stopped, 0 zombie %Cpu(s): 0.0 us, 3.2 sy, 0.0 ni, 96.8 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st MiB Mem : 3780.8 total, 360.5 free, 823.7 used, 2596.6 buff/cache MiB Swap: 0.0 total, 0.0 free, 0.0 used. 2691.2 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 3084 root 10 -10 180812 37704 15780 S 6.7 1.0 219:32.13 AliYunDun 1 root 20 0 178540 10912 8004 S 0.0 0.3 0:12.98 systemd 2 root 20 0 0 0 0 S 0.0 0.0 0:00.26 kthreadd 3 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 rcu_gp 4 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 rcu_par_gp pmap刚好在网上查到一个特别好的例子这里其实刚好遇到一个特别好的例子开始用NMT和pmap来进行分析内存的分布，这里对于jvm的内存，和真正一个进程锁对应的实际内存是如何分布的，有一个特别深入直观的理解 下面是一个pmap的一个基础输出，（版本不同可能输出不一样） START SIZE RSS PSS DIRTY SWAP PERM MAPPING 00000000d54aa000 92824K 92824K 92824K 92824K 0K rw-p [anon] 00000000daf50000 174784K 174784K 174784K 174784K 0K rw-p [anon] 然后对比一下 NMT 的输出 jcmd 14179 VM.native_memory detail 14179: Native Memory Tracking: Total: reserved=653853KB, committed=439409KB - Java Heap (reserved=262144KB, committed=262144KB) (mmap: reserved=262144KB, committed=262144KB) - Class (reserved=82517KB, committed=81725KB) (classes #17828) (malloc=1317KB #26910) (mmap: reserved=81200KB, committed=80408KB) - Thread (reserved=20559KB, committed=20559KB) (thread #58) (stack: reserved=20388KB, committed=20388KB) (malloc=102KB #292) (arena=69KB #114) - Code (reserved=255309KB, committed=41657KB) (malloc=5709KB #11730) (mmap: reserved=249600KB, committed=35948KB) - GC (reserved=1658KB, committed=1658KB) (malloc=798KB #676) (mmap: reserved=860KB, committed=860KB) - Compiler (reserved=130KB, committed=130KB) (malloc=31KB #357) (arena=99KB #3) - Internal (reserved=5039KB, committed=5039KB) (malloc=5007KB #20850) (mmap: reserved=32KB, committed=32KB) - Symbol (reserved=18402KB, committed=18402KB) (malloc=14972KB #221052) (arena=3430KB #1) - Native Memory Tracking (reserved=2269KB, committed=2269KB) (malloc=53KB #1597) (tracking overhead=2216KB) - Arena Chunk (reserved=187KB, committed=187KB) (malloc=187KB) - Unknown (reserved=5640KB, committed=5640KB) (mmap: reserved=5640KB, committed=5640KB) . . . Virtual memory map: [0xceb00000 - 0xcec00000] reserved 1024KB for Class from [0xced00000 - 0xcee00000] reserved 1024KB for Class from . . . [0xcf85e000 - 0xcf8af000] reserved and committed 324KB for Thread Stack from [0xd4eaf000 - 0xd4f00000] reserved and committed 324KB for Thread Stack from [0xf687866e] Thread::record_stack_base_and_size()+0x1be [0xf68818bf] JavaThread::run()+0x2f [0xf67541f9] java_start(Thread*)+0x119 [0xf7606395] start_thread+0xd5 //******************** 注意这里 [0xd5a00000 - 0xe5a00000] reserved 262144KB for Java Heap from //******************** 注意这里 . . . [0xe5e00000 - 0xf4e00000] reserved 245760KB for Code from [0xf737f000 - 0xf7400000] reserved 516KB for GC from [0xf745d000 - 0xf747d000] reserved 128KB for Unknown from [0xf7700000 - 0xf7751000] reserved and committed 324KB for Thread Stack from [0xf7762000 - 0xf776a000] reserved and committed 32KB for Internal from 其中有一行 [0xd5a00000 - 0xe5a00000] reserved 262144KB for Java Heap from 所在的那一行，表示了java的堆内存从0xd5a00000开始辅助上在linux当中，进程的内存分布图，每一块内存是如何分配的就一目了然了 用于对比，附上，虚拟内存空间分布图， vmstatpidstat","categories":[],"tags":[{"name":"-Java","slug":"Java","permalink":"http://kevingeek.github.io/tags/Java/"}]},{"title":"多版本jdk卸载","slug":"多版本jdk卸载","date":"2020-04-14T07:48:53.000Z","updated":"2020-04-14T07:50:02.686Z","comments":true,"path":"2020/04/14/多版本jdk卸载/","link":"","permalink":"http://kevingeek.github.io/2020/04/14/%E5%A4%9A%E7%89%88%E6%9C%ACjdk%E5%8D%B8%E8%BD%BD/","excerpt":"之前在机器上有自己安装jdk，后面因为是centos，因为开发工具包的关系所以又安装了open-jdk，导致了是说同时存在多个版本jdk的问题，","text":"之前在机器上有自己安装jdk，后面因为是centos，因为开发工具包的关系所以又安装了open-jdk，导致了是说同时存在多个版本jdk的问题， 在使用jmap的时候报了如下错误（信息是网上抄的，大致是这个意思） Exception in thread \"main\" sun.jvm.hotspot.runtime.VMVersionMismatchException: Supported versions are 1.5.0, 1.5.0_xx. Target VM is 20.6-b01 所以需要删掉本机的open-sdk，统一成oracle-jdk，如果java -version出现以下提示，说明默认使用的是open-jdk java version \"1.8.0\" OpenJDK Runtime Environment (build 1.8.0-b09) OpenJDK 64-Bit Server VM (build 1.8.0-b09, mixed mode) 最好还是先卸载掉openjdk,在安装Oracle的jdk, ###1.确定JDK的版本：rpm -qa | grep jdk 可能的结果是： libgcj-4.1.2-42.el5java-1.4.2-gcj-compat-1.4.2.0-40jpp.115 ###2.然后卸载： yum -y remove java-1.4.2-gcj-compat-1.4.2.0-40jpp.115 卸载完成以后，可以用whereis java查看java的路径， java: /opt/java/jdk1.8.0_141/bin/java /opt/java/jdk1.8.0_141/jre/bin/java 这时候如果直接用java，可能会报错说 “/usr/bin/java not found”退出终端，并且重新打开一个终端即可","categories":[],"tags":[{"name":"基础","slug":"基础","permalink":"http://kevingeek.github.io/tags/%E5%9F%BA%E7%A1%80/"}]},{"title":"Difference Between Redis And Memcache","slug":"Difference-Between-Redis-And-Memcache","date":"2020-04-08T08:02:02.000Z","updated":"2020-04-09T07:15:04.085Z","comments":true,"path":"2020/04/08/Difference-Between-Redis-And-Memcache/","link":"","permalink":"http://kevingeek.github.io/2020/04/08/Difference-Between-Redis-And-Memcache/","excerpt":"这里主要介绍一下Redis和Memcache的一些异同","text":"这里主要介绍一下Redis和Memcache的一些异同 Redis &amp; Memcache，都是基于内存的存储系统，粗略的说 操作上Redis支持服务端的数据操作，（比如incr），但是Memcache不行，需要将值从服务器上取下来，运算，之后再存回Memcache 内存使用率上Memcache的内存使用率比Redis更低。（和内存分配策略，和数据结构有关） cpu使用上Redis仅支持单核cpu，但是Memcache支持多核cpu 再详细点1. Redis使用很多的这个数据集合，比如下图中列的 string hash list set sorted set 2. 内存管理机制性能：在redis中，允许存储的内容，比实际的物理内存要更大，当物理内存用完之后，就会使用swap分区。swap操作明显会造成io阻塞关于VirtualMachine而memcache不行，仅支持物理内存操作，所以，从纯速度上来说，memcache的性能要比redis要更好。机制:memcache的内存分布如下所示，其实类似于linux文件系统，存在一定的内存浪费 而关于redis的内存分配则是根据基础结构来定的，浪费较少，不过这样的分配容易出现内存碎片问题，官方文档资源则详细得多，我这里直接粘一下好了，一共4点 当key被删除的时候，redis不会立刻释放内存，如果使用了5G内存，然后释放了2G，那么实际上的占用依然会是5G 基于第一点，需要预见到实际的redis占用，如果高峰期可能使用到10G，那么就需要提前预备10G的内存（貌似是废话） 如果申请了5G之后，释放了2G，之后又需要使用内存，那么redis会基本上会重复使用这2G的资源（貌似也是废话） 这样的话，碎片率的当 峰值/平时值 比率较高的时候，碎片率会比较高参考部分：memory-optimization 3. 数据持久化memcache简单粗暴，直接不支持redis支持，两种模式：rdb快照&amp;AOF文件 4. 集群化管理 memcache本身对于集群化是无感知的，就是说，可以启动多个memcache节点，完了在客户端通过算法，将数据hash到各个节点上，通过client端的处理来做一个集群 redis的集群则可以直接在服务端做处理","categories":[{"name":"技术","slug":"技术","permalink":"http://kevingeek.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"In-Memory Data Storage Systems","slug":"In-Memory-Data-Storage-Systems","permalink":"http://kevingeek.github.io/tags/In-Memory-Data-Storage-Systems/"}]},{"title":"2019, New Beginning","slug":"hello-world","date":"2019-01-01T08:02:02.000Z","updated":"2020-04-09T06:37:15.443Z","comments":true,"path":"2019/01/01/hello-world/","link":"","permalink":"http://kevingeek.github.io/2019/01/01/hello-world/","excerpt":"没啥好说的，给您劈个叉吧","text":"没啥好说的，给您劈个叉吧","categories":[{"name":"日常","slug":"日常","permalink":"http://kevingeek.github.io/categories/%E6%97%A5%E5%B8%B8/"}],"tags":[]},{"title":"苦命管家之巧解草莓风波","slug":"Stawberry","date":"2017-02-19T10:24:50.000Z","updated":"2020-04-09T04:19:33.058Z","comments":true,"path":"2017/02/19/Stawberry/","link":"","permalink":"http://kevingeek.github.io/2017/02/19/Stawberry/","excerpt":"阿哲是村东边的大户，他有一个特别厉害的管家，能说会道，智商超人，说到草莓风波…","text":"阿哲是村东边的大户，他有一个特别厉害的管家，能说会道，智商超人，说到草莓风波… 事起老爷平日没啥爱好，年前下苏杭时候碰巧尝了一次草莓，至此每日念念不忘，招来管家… 原来是老爷嘴馋了 嘴馋也有讲究，不是胡吃海喝，咱们要持续性发展… 草莓这物件，这年代也没冰箱什么的，最新鲜的就是每日采摘，老爷做的长远打算，每日一醒就对草莓心心念念，所以啊，就想越早越好，晚来一点也没关系，但是必须是今天摘的才行，但是一天都没吃到好草莓，我可是要发飙哦！ 还有，这草莓虽好，但是也不能贪杯哦…啊呸，不能多吃，每日一袋是为最好，之后来的，就把他们退掉吧！ 老爷想要的是什么对于老爷的想法，管家自然是摸得透彻，稍作盘算，就知道老爷想的是啥 每天都需要消耗一批草莓(尽最大努力) 每天仅吃一批草莓 只吃当日最新鲜的、质量过关的草莓，至于是谁提供的并不重要 如果有多余的或者不合格的草莓，则需要把他们处理掉(退货) 召集商家任务吩咐下去，让管家一手操办，老板提出了需求，那管家就只能跑跑腿了～ 要拿到草莓，那得首先联系一下草莓供应商是个什么情况 几日之后，很快就有了消息，这几家供应商，因为草莓属于现摘，每日的情况都不一样，供应商每天送来都货物质量也都参差不齐，需要管家一一验过如果货物质量不行，那么就只能退货啦，又或者我们老爷当日只能吃过草莓了，那么抱歉，你这批货我只能退啦，要是你来的时候，管家还在验上家的货，那你可以碰碰运气，万一上家的货物不过关呢，是吧～ 简而言之，市场竞争真是激烈呀！ 那么提炼一下： 不保证每日都有货物 不保证货物的质量 不保证到货时间 接受退货 供应商在货物送到之前，并不知晓老爷今日是否已经享用了草莓 嗯，任性的供应商提供的服务还真是不怎么可靠啊，但是这总难不住聪明的管家，咋一看，虽然每一家货物提供商并不能提供完全可靠的服务，但是我多喊几家一起上，那么老爷的需求还是可以尽量满足的嘛，想到这里，管家就被自己的聪明才智锁折服了，心里还有点小激动呢 (ಡωಡ)hiahiahia 心中一阵盘算之后，通知供应商们召集到院中开了一次集体会议…. 一个月黑风高的夜晚众商家，今日将大家召集到此，是为了通知各商家之后咱们的统一供货方式，一方面尽量保证老爷的要求，一方面呢，也是和大家打个招呼，咱们以后就按照这个法子来，互通有无嘛 之后每日，若各位货物到后，可将货物先置放于院中，然后由知晓我，待我来对货物进行验收，验收通过之后，向你发放当日款项。若通知我时，我已找到一批新鲜的货物，那么你货的新鲜程度不如上家，自然是输了，那么我就无法给你款项，只能将货退还给你。若我还在验货，那你可以再等等，若之前的货物不合格，那么你可以等等，若上家的货物不符合老爷的要求，那么我就可以来验你的货啦～ 各商家见管家提出如此妥善的注意，事少，也不用和别家伤和气，一切买卖全凭本事，一个一个也摩拳擦掌，纷纷表示赞同 单机版一段时日之后，老爷如愿吃上了想要的草莓🍓，管家也将此方法记录了下来，以便改进与学习 :) 商家p1、p2属于集合P(Provider)，商家提供的服务都是同质的，可以归为一类，分别为 送货 deliver 验货 validate 退货 takeBack 而管家g(governor)的状态分为几种 尚未验货 available 正在验货 validating 验货结束 unavailable 那么商家所执行的步骤可以用如下伪代码表示： public class ProviderDeliver { public void dailyWork(Provider p, Governor g){} p.deliver(); if (g.unavailable()) { p.takeBack(); return ; } while (g.validating()) { // simply wait } if (g.available()) { p.validate(); } else { p.takeBack(); } } 分布式版哎呀，老爷一高兴，赏金给得特别高，各路商家接踵而至，管家要忙不过来了，于是吩咐下去几个家丁，分别接待商户，检查依然由管家亲自操作，但商户无需等待，仅需要将货物放在府中，退货由家丁完成，而商户也不直接与管家接触，由家丁负责商家和管家之间的沟通，管家通过府邸中的旗帜表示自己目前正在验货、休息、验货完毕 那么整体的流程作一下简单转换，对商户来说，流程更加简单 /** * * Created by kevin on 20/02/2017. */ public class Strawberry { static AtomicInteger errorCount = new AtomicInteger(0); static AtomicInteger takeBackCount = new AtomicInteger(0); static AtomicInteger consumedCount = new AtomicInteger(0); static AtomicInteger acceptedCount = new AtomicInteger(0); static Random r = new Random(); static class ProviderDeliver2 { private Provider p; ProviderDeliver2(String name) { this.p = new Provider(name); } void dailyWork(int day) { Merchandise m = p.deliver(); // 运送货物 Worker worker = Worker.of(this, day); // 随便找个家丁，并把货物交给他 worker.process(m); // 家丁来处理货物 } void takeBack(Merchandise m) { int res = m.getTime().incrementAndGet(); if (res == 1) { takeBackCount.incrementAndGet(); } else if (res > 1) { System.out.println(\"fail! operate \" + res ); errorCount.incrementAndGet(); } } } static class Worker { private Governor g; private ProviderDeliver2 pd2; Worker(ProviderDeliver2 pd2, Governor g) { this.pd2 = pd2; this.g = g; } static Worker of(ProviderDeliver2 pd2, int day) { return new Worker(pd2, Governor.getInstance(day)); } void process(Merchandise m) { g.validate(this, m); } void takeBack(Merchandise m) { pd2.takeBack(m); } } static class Governor { private AtomicBoolean available = new AtomicBoolean(true); private AtomicBoolean validating = new AtomicBoolean(false); private Queue queue = Queues.newConcurrentLinkedQueue(); private int date; private static ConcurrentHashMap MAP = new ConcurrentHashMap(); static Governor getInstance(int day) { return MAP.computeIfAbsent(day, Governor::new); } boolean available() { return available.get(); } private Governor(int date) { this.date = date; } void validate(Worker worker, Merchandise m) { try { if (!available()) { worker.takeBack(m); return; } this.addMerchandise(m); if (!validating.compareAndSet(false, true)) { return; } if (!available()) { cleanAll(worker); return; } while (!queue.isEmpty()) { Merchandise item = queue.poll(); if (available() && item.isGood()) { available.set(false); acceptedCount.incrementAndGet(); } else { worker.takeBack(item); } } validating.set(false); } finally { consumedCount.incrementAndGet(); } } private void cleanAll(Worker worker) { while (!queue.isEmpty()) { Merchandise item = queue.poll(); worker.takeBack(item); } } void addMerchandise(Merchandise m) { queue.add(m); } } public static class Provider { private String name; Provider(String name) { this.name = name; } Merchandise deliver() { return new Merchandise(this.name + System.nanoTime()); } } static class Merchandise { private String name; private AtomicInteger time = new AtomicInteger(0); private long quality = r.nextInt(100); AtomicInteger getTime() { return time; } Merchandise(String name) { this.name = name; } @Override public boolean equals(Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Merchandise that = (Merchandise) o; return name != null ? name.equals(that.name) : that.name == null; } @Override public int hashCode() { return name != null ? name.hashCode() : 0; } boolean isGood() { // return true; return quality < 80; } } public static void main(String[] args) throws InterruptedException { // 模仿5个商家，连续提供500日的情况 int k = 0; for (int day = 0; day < 500; day++) { int tmpDay = day; for (int i = 0; i < 5; i++) { new Thread(() -> new ProviderDeliver2(String.valueOf(tmpDay)).dailyWork(tmpDay)).start(); k++; } } while (k != consumedCount.get()) { Thread.sleep(10); } System.out.println(\"done\"); System.out.println(errorCount.get()); //0 System.out.println(takeBackCount.get()); // System.out.println(acceptedCount.get()); // System.out.println(consumedCount.get()); // } }","categories":[{"name":"日常","slug":"日常","permalink":"http://kevingeek.github.io/categories/%E6%97%A5%E5%B8%B8/"}],"tags":[{"name":"Algorithm","slug":"Algorithm","permalink":"http://kevingeek.github.io/tags/Algorithm/"},{"name":"分布式","slug":"分布式","permalink":"http://kevingeek.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"限流之RateLimiter","slug":"RateLimiter","date":"2016-10-24T12:59:25.000Z","updated":"2020-04-09T04:19:33.057Z","comments":true,"path":"2016/10/24/RateLimiter/","link":"","permalink":"http://kevingeek.github.io/2016/10/24/RateLimiter/","excerpt":"高并发三板斧,缓存、降级和限流","text":"高并发三板斧,缓存、降级和限流 老话说得好，要想服务器耍得好，三板斧不能少，今天我们就来看看其中的一板斧–‘限流’ 什么是限流 简单明了的说，在系统当中，有一些第三方应用具有并行能力上限(比如某些垄断行业提供的接口)，你多请求了直接给你返回错误码，还有一些具体的服务，比如秒杀等，仅允许一定的速率来访问特定的资源，在这些应用场景中，就需要用到限流来完成这些事情。 一些通常的case，比如说限制总并发数(DB)，瞬间并发数(Nginx limit_conn)，限制平均速率(RateLimiter)等。而我们今天所要具体讨论的，就是限制平均速率的方法。 两大算法 当然，在此之前我们先来讨论一下限流的两大算法：漏桶、令牌桶。 漏桶 令牌桶 ReteLimiter好啦,那就让我们来看一下令牌桶算法的具体应用,强大的guava包的RateLimiter已经实现了限流,使用的是令牌桶算法,并且可以允许一定程度的请求激增,看起来是非常好的东西简单来说,看注释上来说,是通过时间的换算来等价于令牌的存储的,具体的实现方法,看具体的代码实现吧 /* * Copyright (C) 2012 The Guava Authors * * Licensed under the Apache License, Version 2.0 (the \"License\"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at 屌屌的，先说明一下是基于Apache2的哦～ * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.google.common.util.concurrent; import com.google.common.annotations.Beta; import com.google.common.annotations.VisibleForTesting; import com.google.common.base.Preconditions; import com.google.common.base.Ticker; import java.util.concurrent.TimeUnit; import javax.annotation.concurrent.ThreadSafe; /** * A rate limiter. Conceptually, a rate limiter distributes permits at a * configurable rate. Each {@link #acquire()} blocks if necessary until a permit is * available, and then takes it. Once acquired, permits need not be released. 字面意思上来说，rateLimiter当然是按照一个给定的速率来进行派发令牌啦～ 执行acquire()方法，会一直阻塞，直到有一个令牌是可用的，然后获得这个令牌，一旦令牌被获得! 令牌是不需要被 `释放` 的! * Rate limiters are often used to restrict the rate at which some * physical or logical resource is accessed. This is in contrast to {@link * java.util.concurrent.Semaphore} which restricts the number of concurrent * accesses instead of the rate (note though that concurrency and rate are closely related, * e.g. see Little's Law). RateLimiter 常常被用来限制某些资源的访问速率。 这和Semaphore不同，Semaphore是用来限制 并发数而不是速率，这两者还是有不同的。 * A {@code RateLimiter} is defined primarily by the rate at which permits * are issued. Absent additional configuration, permits will be distributed at a * fixed rate, defined in terms of permits per second. Permits will be distributed * smoothly, with the delay between individual permits being adjusted to ensure * that the configured rate is maintained. 如果没有额外的配置，令牌会以固定的速率派发，这个速率以每秒为单位计算。 令牌将会以平滑的速率派发，单位令牌之间的间隔会被良好调配以保障之前设定好的速率。 * * It is possible to configure a {@code RateLimiter} to have a warmup * period during which time the permits issued each second steadily increases until * it hits the stable rate. 通过配置，也可以使用一个预热的阶段，在这个阶段中每秒分发的令牌数将会递增直到达到边界值为止 * * As an example, imagine that we have a list of tasks to execute, but we don't want to * submit more than 2 per second: 一个简单的例子，有一个任务队列需要执行，但是我们不想每秒同时执行的任务超过2个，那么可以这样写 * {@code * final RateLimiter rateLimiter = RateLimiter.create(2.0); // rate is \"2 permits per second\" * void submitTasks(List tasks, Executor executor) { * for (Runnable task : tasks) { * rateLimiter.acquire(); // may wait * executor.execute(task); * } * } *} * * As another example, imagine that we produce a stream of data, and we want to cap it * at 5kb per second. This could be accomplished by requiring a permit per byte, and specifying * a rate of 5000 permits per second: 另一个例子就是，想象一下正在处理一个数据流，然后我们想每秒处理5kb。这里的处理方式，为每个byte分配一个令牌， 并且指定每秒有5000个令牌。 * {@code * final RateLimiter rateLimiter = RateLimiter.create(5000.0); // rate = 5000 permits per second * void submitPacket(byte[] packet) { * rateLimiter.acquire(packet.length); * networkService.send(packet); * } *} * * It is important to note that the number of permits requested never * affect the throttling of the request itself (an invocation to {@code acquire(1)} * and an invocation to {@code acquire(1000)} will result in exactly the same throttling, if any), * but it affects the throttling of the next request. I.e., if an expensive task * arrives at an idle RateLimiter, it will be granted immediately, but it is the next * request that will experience extra throttling, thus paying for the cost of the expensive * task. 作者提到了很重要的一点，当前请求的令牌数量并不会阻止当前的请求，acquire(1)和acquire(1000)会导致相同的结果， 如果当前的请求消耗了特别多的令牌，那么是由“下一个请求\"来偿还当前这个请求所耗费的令牌。 这里有点绕，具体还是看代码吧 * * Note: {@code RateLimiter} does not provide fairness guarantees. 嗯...这就是不公平的，就像这个世界一样 =。= face and embrace it * * @author Dimitris Andreou * @since 13.0 */ // TODO(user): switch to nano precision. A natural unit of cost is \"bytes\", and a micro precision // would mean a maximum rate of \"1MB/s\", which might be small in some cases. @ThreadSafe @Beta // wow， 原来这玩意还只是个Beta版本呀～ public abstract class RateLimiter { /* * How is the RateLimiter designed, and why? * * The primary feature of a RateLimiter is its \"stable rate\", the maximum rate that * is should allow at normal conditions. This is enforced by \"throttling\" incoming * requests as needed, i.e. compute, for an incoming request, the appropriate throttle time, * and make the calling thread wait as much. 对于RateLimiter最主要的特性就是“稳定的速率”，在通常情况下，允许以最高的速率进行运作。 后面的不知道怎么翻译 * * The simplest way to maintain a rate of QPS is to keep the timestamp of the last * granted request, and ensure that (1/QPS) seconds have elapsed since then. For example, * for a rate of QPS=5 (5 tokens per second), if we ensure that a request isn't granted * earlier than 200ms after the the last one, then we achieve the intended rate. * If a request comes and the last request was granted only 100ms ago, then we wait for * another 100ms. At this rate, serving 15 fresh permits (i.e. for an acquire(15) request) * naturally takes 3 seconds. 最简单的控制QPS的办法,就是控制时间戳嘛,只要保证自从上一次发送令牌到现在已经经过了(1/QPS)秒即可,那么 这样就保证了基本的QPS. * It is important to realize that such a RateLimiter has a very superficial memory * of the past: it only remembers the last request. What if the RateLimiter was unused for * a long period of time, then a request arrived and was immediately granted? * This RateLimiter would immediately forget about that past underutilization. This may * result in either underutilization or overflow, depending on the real world consequences * of not using the expected rate. 上述做法虽然简单粗暴,但是有一个很重要的一点,就是它“对于过去的认识并不充分”--它仅记住了上一次的请求, 如果RateLimiter很久不被使用，新来了一个请求,并且这个请求很快会获得指令,那么它机会\"忘记\"掉之前的低使用率, 这可能会导致一些问题,具体取决于具体的场景. * Past underutilization could mean that excess resources are available. Then, the RateLimiter * should speed up for a while, to take advantage of these resources. This is important * when the rate is applied to networking (limiting bandwidth), where past underutilization * typically translates to \"almost empty buffers\", which can be filled immediately. 过去的低使用率意味着有剩余的可用资源,所以RateLimiter可以提速(??? 这里不清楚应该怎么翻译)来使用这些资源, * On the other hand, past underutilization could mean that \"the server responsible for * handling the request has become less ready for future requests\", i.e. its caches become * stale, and requests become more likely to trigger expensive operations (a more extreme * case of this example is when a server has just booted, and it is mostly busy with getting * itself up to speed). 另个方面讲,低使用率意味着处理这些请求的服务有可能还没有准备好使用这些请求,比如说当服务使用到cache时, 那么在长时间的间隔之后的突然请求,有可能会造成cache的大量miss,更极端的请求是当服务刚启动时. * To deal with such scenarios, we add an extra dimension, that of \"past underutilization\", * modeled by \"storedPermits\" variable. This variable is zero when there is no * underutilization, and it can grow up to maxStoredPermits, for sufficiently large * underutilization. So, the requested permits, by an invocation acquire(permits), * are served from: * - stored permits (if available) * - fresh permits (for any remaining permits) 作者使用了一个额外的维度来描述过去的低使用率, storedPermits 当新请求令牌时,令牌从stored permits和fresh permits两个地方获得 * How this works is best explained with an example: * * For a RateLimiter that produces 1 token per second, every second * that goes by with the RateLimiter being unused, we increase storedPermits by 1. * Say we leave the RateLimiter unused for 10 seconds (i.e., we expected a request at time * X, but we are at time X + 10 seconds before a request actually arrives; this is * also related to the point made in the last paragraph), thus storedPermits * becomes 10.0 (assuming maxStoredPermits >= 10.0). At that point, a request of acquire(3) * arrives. We serve this request out of storedPermits, and reduce that to 7.0 (how this is * translated to throttling time is discussed later). Immediately after, assume that an * acquire(10) request arriving. We serve the request partly from storedPermits, * using all the remaining 7.0 permits, and the remaining 3.0, we serve them by fresh permits * produced by the rate limiter. storedPermits其实是一个预备的库存的意思,如果其中还有令牌预存,就直接取,如果不够的话,不足的部分用fresh permits来弥补 当然,作者将这些补偿的公式都转换为时间上的计算,计算方式后面再看 * We already know how much time it takes to serve 3 fresh permits: if the rate is * \"1 token per second\", then this will take 3 seconds. But what does it mean to serve 7 * stored permits? As explained above, there is no unique answer. If we are primarily * interested to deal with underutilization, then we want stored permits to be given out * /faster/ than fresh ones, because underutilization = free resources for the taking. * If we are primarily interested to deal with overflow, then stored permits could * be given out /slower/ than fresh ones. Thus, we require a (different in each case) * function that translates storedPermits to throtting time. 其实新请求3个令牌的时间是容易计算的,那么问题就在于如何表示\"提供7个stored permits\"? 作者说, 1:如果要应对的低使用率,那么在提供stored permits的时候就需要比fresh permits要\"快\"一些,因为 实际上stored permits就意味着是\"闲置的资源\", 2:如果要应对的是过高使用率,那么stored permits就需要慢一些 所以作者require了一个function来将storePermits转化为throtting time OK,下面就是算法描述,看不懂,先看代码~ * This role is played by storedPermitsToWaitTime(double storedPermits, double permitsToTake). * The underlying model is a continuous function mapping storedPermits * (from 0.0 to maxStoredPermits) onto the 1/rate (i.e. intervals) that is effective at the given * storedPermits. \"storedPermits\" essentially measure unused time; we spend unused time * buying/storing permits. Rate is \"permits / time\", thus \"1 / rate = time / permits\". * Thus, \"1/rate\" (time / permits) times \"permits\" gives time, i.e., integrals on this * function (which is what storedPermitsToWaitTime() computes) correspond to minimum intervals * between subsequent requests, for the specified number of requested permits. * * Here is an example of storedPermitsToWaitTime: * If storedPermits == 10.0, and we want 3 permits, we take them from storedPermits, * reducing them to 7.0, and compute the throttling for these as a call to * storedPermitsToWaitTime(storedPermits = 10.0, permitsToTake = 3.0), which will * evaluate the integral of the function from 7.0 to 10.0. * * Using integrals guarantees that the effect of a single acquire(3) is equivalent * to { acquire(1); acquire(1); acquire(1); }, or { acquire(2); acquire(1); }, etc, * since the integral of the function in [7.0, 10.0] is equivalent to the sum of the * integrals of [7.0, 8.0], [8.0, 9.0], [9.0, 10.0] (and so on), no matter * what the function is. This guarantees that we handle correctly requests of varying weight * (permits), /no matter/ what the actual function is - so we can tweak the latter freely. * (The only requirement, obviously, is that we can compute its integrals). * * Note well that if, for this function, we chose a horizontal line, at height of exactly * (1/QPS), then the effect of the function is non-existent: we serve storedPermits at * exactly the same cost as fresh ones (1/QPS is the cost for each). We use this trick later. * * If we pick a function that goes /below/ that horizontal line, it means that we reduce * the area of the function, thus time. Thus, the RateLimiter becomes /faster/ after a * period of underutilization. If, on the other hand, we pick a function that * goes /above/ that horizontal line, then it means that the area (time) is increased, * thus storedPermits are more costly than fresh permits, thus the RateLimiter becomes * /slower/ after a period of underutilization. * * Last, but not least: consider a RateLimiter with rate of 1 permit per second, currently * completely unused, and an expensive acquire(100) request comes. It would be nonsensical * to just wait for 100 seconds, and /then/ start the actual task. Why wait without doing * anything? A much better approach is to /allow/ the request right away (as if it was an * acquire(1) request instead), and postpone /subsequent/ requests as needed. In this version, * we allow starting the task immediately, and postpone by 100 seconds future requests, * thus we allow for work to get done in the meantime instead of waiting idly. * * This has important consequences: it means that the RateLimiter doesn't remember the time * of the _last_ request, but it remembers the (expected) time of the _next_ request. This * also enables us to tell immediately (see tryAcquire(timeout)) whether a particular * timeout is enough to get us to the point of the next scheduling time, since we always * maintain that. And what we mean by \"an unused RateLimiter\" is also defined by that * notion: when we observe that the \"expected arrival time of the next request\" is actually * in the past, then the difference (now - past) is the amount of time that the RateLimiter * was formally unused, and it is that amount of time which we translate to storedPermits. * (We increase storedPermits with the amount of permits that would have been produced * in that idle time). So, if rate == 1 permit per second, and arrivals come exactly * one second after the previous, then storedPermits is _never_ increased -- we would only * increase it for arrivals _later_ than the expected one second. */ /** * Creates a {@code RateLimiter} with the specified stable throughput, given as * \"permits per second\" (commonly referred to as QPS, queries per second). * * The returned {@code RateLimiter} ensures that on average no more than {@code * permitsPerSecond} are issued during any given second, with sustained requests * being smoothly spread over each second. When the incoming request rate exceeds * {@code permitsPerSecond} the rate limiter will release one permit every {@code * (1.0 / permitsPerSecond)} seconds. When the rate limiter is unused, * bursts of up to {@code permitsPerSecond} permits will be allowed, with subsequent * requests being smoothly limited at the stable rate of {@code permitsPerSecond}. RateLimiter保证了 * @param permitsPerSecond the rate of the returned {@code RateLimiter}, measured in * how many permits become available per second. */ // TODO(user): \"This is equivalent to // {@code createWithCapacity(permitsPerSecond, 1, TimeUnit.SECONDS)}\". public static RateLimiter create(double permitsPerSecond) { /* * The default RateLimiter configuration can save the unused permits of up to one second. * This is to avoid unnecessary stalls in situations like this: A RateLimiter of 1qps, * and 4 threads, all calling acquire() at these moments: * * T0 at 0 seconds * T1 at 1.05 seconds * T2 at 2 seconds * T3 at 3 seconds * * Due to the slight delay of T1, T2 would have to sleep till 2.05 seconds, * and T3 would also have to sleep till 3.05 seconds. */ return create(SleepingTicker.SYSTEM_TICKER, permitsPerSecond); } @VisibleForTesting static RateLimiter create(SleepingTicker ticker, double permitsPerSecond) { RateLimiter rateLimiter = new Bursty(ticker, 1.0 /* maxBurstSeconds */); rateLimiter.setRate(permitsPerSecond); return rateLimiter; } /** * Creates a {@code RateLimiter} with the specified stable throughput, given as * \"permits per second\" (commonly referred to as QPS, queries per second), and a * warmup period, during which the {@code RateLimiter} smoothly ramps up its rate, * until it reaches its maximum rate at the end of the period (as long as there are enough * requests to saturate it). Similarly, if the {@code RateLimiter} is left unused for * a duration of {@code warmupPeriod}, it will gradually return to its \"cold\" state, * i.e. it will go through the same warming up process as when it was first created. * * The returned {@code RateLimiter} is intended for cases where the resource that actually * fulfills the requests (e.g., a remote server) needs \"warmup\" time, rather than * being immediately accessed at the stable (maximum) rate. * * The returned {@code RateLimiter} starts in a \"cold\" state (i.e. the warmup period * will follow), and if it is left unused for long enough, it will return to that state. * * @param permitsPerSecond the rate of the returned {@code RateLimiter}, measured in * how many permits become available per second * @param warmupPeriod the duration of the period where the {@code RateLimiter} ramps up its * rate, before reaching its stable (maximum) rate * @param unit the time unit of the warmupPeriod argument */ public static RateLimiter create(double permitsPerSecond, long warmupPeriod, TimeUnit unit) { return create(SleepingTicker.SYSTEM_TICKER, permitsPerSecond, warmupPeriod, unit); } @VisibleForTesting static RateLimiter create( SleepingTicker ticker, double permitsPerSecond, long warmupPeriod, TimeUnit unit) { RateLimiter rateLimiter = new WarmingUp(ticker, warmupPeriod, unit); rateLimiter.setRate(permitsPerSecond); return rateLimiter; } @VisibleForTesting static RateLimiter createWithCapacity( SleepingTicker ticker, double permitsPerSecond, long maxBurstBuildup, TimeUnit unit) { double maxBurstSeconds = unit.toNanos(maxBurstBuildup) / 1E+9; Bursty rateLimiter = new Bursty(ticker, maxBurstSeconds); rateLimiter.setRate(permitsPerSecond); return rateLimiter; } /** * The underlying timer; used both to measure elapsed time and sleep as necessary. A separate * object to facilitate testing. */ private final SleepingTicker ticker; /** * The timestamp when the RateLimiter was created; used to avoid possible overflow/time-wrapping * errors. */ private final long offsetNanos; /** * The currently stored permits. */ double storedPermits; /** * The maximum number of stored permits. */ double maxPermits; /** * The interval between two unit requests, at our stable rate. E.g., a stable rate of 5 permits * per second has a stable interval of 200ms. */ volatile double stableIntervalMicros; private final Object mutex = new Object(); /** * The time when the next request (no matter its size) will be granted. After granting a request, * this is pushed further in the future. Large requests push this further than small requests. */ private long nextFreeTicketMicros = 0L; // could be either in the past or future private RateLimiter(SleepingTicker ticker) { this.ticker = ticker; this.offsetNanos = ticker.read(); } /** * Updates the stable rate of this {@code RateLimiter}, that is, the * {@code permitsPerSecond} argument provided in the factory method that * constructed the {@code RateLimiter}. Currently throttled threads will not * be awakened as a result of this invocation, thus they do not observe the new rate; * only subsequent requests will. * * Note though that, since each request repays (by waiting, if necessary) the cost * of the previous request, this means that the very next request * after an invocation to {@code setRate} will not be affected by the new rate; * it will pay the cost of the previous request, which is in terms of the previous rate. * * The behavior of the {@code RateLimiter} is not modified in any other way, * e.g. if the {@code RateLimiter} was configured with a warmup period of 20 seconds, * it still has a warmup period of 20 seconds after this method invocation. * * @param permitsPerSecond the new stable rate of this {@code RateLimiter}. */ public final void setRate(double permitsPerSecond) { Preconditions.checkArgument(permitsPerSecond > 0.0 && !Double.isNaN(permitsPerSecond), \"rate must be positive\"); synchronized (mutex) { resync(readSafeMicros()); double stableIntervalMicros = TimeUnit.SECONDS.toMicros(1L) / permitsPerSecond; this.stableIntervalMicros = stableIntervalMicros; doSetRate(permitsPerSecond, stableIntervalMicros); } } abstract void doSetRate(double permitsPerSecond, double stableIntervalMicros); /** * Returns the stable rate (as {@code permits per seconds}) with which this * {@code RateLimiter} is configured with. The initial value of this is the same as * the {@code permitsPerSecond} argument passed in the factory method that produced * this {@code RateLimiter}, and it is only updated after invocations * to {@linkplain #setRate}. */ public final double getRate() { return TimeUnit.SECONDS.toMicros(1L) / stableIntervalMicros; } /** * Acquires a permit from this {@code RateLimiter}, blocking until the request can be granted. * * This method is equivalent to {@code acquire(1)}. */ public void acquire() { acquire(1); } /** * Acquires the given number of permits from this {@code RateLimiter}, blocking until the * request be granted. * * @param permits the number of permits to acquire */ public void acquire(int permits) { checkPermits(permits); long microsToWait; synchronized (mutex) { microsToWait = reserveNextTicket(permits, readSafeMicros()); } ticker.sleepMicrosUninterruptibly(microsToWait); } /** * Acquires a permit from this {@code RateLimiter} if it can be obtained * without exceeding the specified {@code timeout}, or returns {@code false} * immediately (without waiting) if the permit would not have been granted * before the timeout expired. * * This method is equivalent to {@code tryAcquire(1, timeout, unit)}. * * @param timeout the maximum time to wait for the permit * @param unit the time unit of the timeout argument * @return {@code true} if the permit was acquired, {@code false} otherwise */ public boolean tryAcquire(long timeout, TimeUnit unit) { return tryAcquire(1, timeout, unit); } /** * Acquires permits from this {@link RateLimiter} if it can be acquired immediately without delay. * * * This method is equivalent to {@code tryAcquire(permits, 0, anyUnit)}. * * @param permits the number of permits to acquire * @return {@code true} if the permits were acquired, {@code false} otherwise * @since 14.0 */ public boolean tryAcquire(int permits) { return tryAcquire(permits, 0, TimeUnit.MICROSECONDS); } /** * Acquires a permit from this {@link RateLimiter} if it can be acquired immediately without * delay. * * * This method is equivalent to {@code tryAcquire(1)}. * * @return {@code true} if the permit was acquired, {@code false} otherwise * @since 14.0 */ public boolean tryAcquire() { return tryAcquire(1, 0, TimeUnit.MICROSECONDS); } /** * Acquires the given number of permits from this {@code RateLimiter} if it can be obtained * without exceeding the specified {@code timeout}, or returns {@code false} * immediately (without waiting) if the permits would not have been granted * before the timeout expired. * * @param permits the number of permits to acquire * @param timeout the maximum time to wait for the permits * @param unit the time unit of the timeout argument * @return {@code true} if the permits were acquired, {@code false} otherwise */ public boolean tryAcquire(int permits, long timeout, TimeUnit unit) { long timeoutMicros = unit.toMicros(timeout); checkPermits(permits); long microsToWait; synchronized (mutex) { long nowMicros = readSafeMicros(); if (nextFreeTicketMicros > nowMicros + timeoutMicros) { return false; } else { microsToWait = reserveNextTicket(permits, nowMicros); } } ticker.sleepMicrosUninterruptibly(microsToWait); return true; } private static void checkPermits(int permits) { Preconditions.checkArgument(permits > 0, \"Requested permits must be positive\"); } /** * Reserves next ticket and returns the wait time that the caller must wait for. */ private long reserveNextTicket(double requiredPermits, long nowMicros) { resync(nowMicros); long microsToNextFreeTicket = nextFreeTicketMicros - nowMicros; double storedPermitsToSpend = Math.min(requiredPermits, this.storedPermits); double freshPermits = requiredPermits - storedPermitsToSpend; long waitMicros = storedPermitsToWaitTime(this.storedPermits, storedPermitsToSpend) + (long) (freshPermits * stableIntervalMicros); this.nextFreeTicketMicros = nextFreeTicketMicros + waitMicros; this.storedPermits -= storedPermitsToSpend; return microsToNextFreeTicket; } /** * Translates a specified portion of our currently stored permits which we want to * spend/acquire, into a throttling time. Conceptually, this evaluates the integral * of the underlying function we use, for the range of * [(storedPermits - permitsToTake), storedPermits]. * * This always holds: {@code 0","categories":[{"name":"Java","slug":"Java","permalink":"http://kevingeek.github.io/categories/Java/"}],"tags":[{"name":"RateLimiter","slug":"RateLimiter","permalink":"http://kevingeek.github.io/tags/RateLimiter/"},{"name":"Server","slug":"Server","permalink":"http://kevingeek.github.io/tags/Server/"}]},{"title":"MarkDown 写法乱弹","slug":"MarkDown","date":"2016-07-25T13:17:17.000Z","updated":"2020-04-09T04:19:33.057Z","comments":true,"path":"2016/07/25/MarkDown/","link":"","permalink":"http://kevingeek.github.io/2016/07/25/MarkDown/","excerpt":"这是超链接备忘全在这上面MarkDown语法","text":"这是超链接备忘全在这上面MarkDown语法 This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisseid sem consectetuer libero luctus adipiscing. 标题哦This is an H1============= This is an H2第一次来这边写日志，算是第一篇真正意义上的个人blog日志，好的开始，Hello World！ Use the printf() function. 以下是Java代码 System.out.println(\"hello world!\"); 这是很重要的 line_number line_two 恩，这是星号 恩，这是加号 分割符 第一点 第二点","categories":[{"name":"feel","slug":"feel","permalink":"http://kevingeek.github.io/categories/feel/"}],"tags":[{"name":"First","slug":"First","permalink":"http://kevingeek.github.io/tags/First/"},{"name":"Second","slug":"Second","permalink":"http://kevingeek.github.io/tags/Second/"}]}],"categories":[{"name":"技术","slug":"技术","permalink":"http://kevingeek.github.io/categories/%E6%8A%80%E6%9C%AF/"},{"name":"日常","slug":"日常","permalink":"http://kevingeek.github.io/categories/%E6%97%A5%E5%B8%B8/"},{"name":"Java","slug":"Java","permalink":"http://kevingeek.github.io/categories/Java/"},{"name":"feel","slug":"feel","permalink":"http://kevingeek.github.io/categories/feel/"}],"tags":[{"name":"-Java","slug":"Java","permalink":"http://kevingeek.github.io/tags/Java/"},{"name":"基础","slug":"基础","permalink":"http://kevingeek.github.io/tags/%E5%9F%BA%E7%A1%80/"},{"name":"In-Memory Data Storage Systems","slug":"In-Memory-Data-Storage-Systems","permalink":"http://kevingeek.github.io/tags/In-Memory-Data-Storage-Systems/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://kevingeek.github.io/tags/Algorithm/"},{"name":"分布式","slug":"分布式","permalink":"http://kevingeek.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"RateLimiter","slug":"RateLimiter","permalink":"http://kevingeek.github.io/tags/RateLimiter/"},{"name":"Server","slug":"Server","permalink":"http://kevingeek.github.io/tags/Server/"},{"name":"First","slug":"First","permalink":"http://kevingeek.github.io/tags/First/"},{"name":"Second","slug":"Second","permalink":"http://kevingeek.github.io/tags/Second/"}]}