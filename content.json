{"meta":{"title":"小飞侠","subtitle":null,"description":null,"author":"kevin","url":"http://kevingeek.github.io"},"pages":[],"posts":[{"title":"2019, New Beginning","slug":"hello-world","date":"2020-04-09T04:19:33.058Z","updated":"2020-04-09T04:19:33.058Z","comments":true,"path":"2020/04/09/hello-world/","link":"","permalink":"http://kevingeek.github.io/2020/04/09/hello-world/","excerpt":"没啥好说的，给您劈个叉吧","text":"没啥好说的，给您劈个叉吧","categories":[{"name":"日常","slug":"日常","permalink":"http://kevingeek.github.io/categories/日常/"}],"tags":[]},{"title":"Difference Between Redis And Memcache","slug":"Difference-Between-Redis-And-Memcache","date":"2020-04-08T08:02:02.000Z","updated":"2020-04-09T04:21:08.376Z","comments":true,"path":"2020/04/08/Difference-Between-Redis-And-Memcache/","link":"","permalink":"http://kevingeek.github.io/2020/04/08/Difference-Between-Redis-And-Memcache/","excerpt":"这里主要介绍一下Redis和Memcache的一些异同","text":"这里主要介绍一下Redis和Memcache的一些异同 Redis &amp; Memcache，都是基于内存的存储系统，粗略的说 操作上Redis支持服务端的数据操作，（比如incr），但是Memcache不行，需要将值从服务器上取下来，运算，之后再存回Memcache 内存使用率上Memcache的内存使用率比Redis更低。（和内存分配策略，和数据结构有关） cpu使用上Redis仅支持单核cpu，但是Memcache支持多核cpu 再详细点1. Redis使用很多的这个数据集合，比如下图中列的 string hash list set sorted set 2. 内存管理机制性能：在redis中，允许存储的内容，比实际的物理内存要更大，当物理内存用完之后，就会使用swap分区。swap操作明显会造成io阻塞关于VirtualMachine而memcache不行，仅支持物理内存操作，所以，从纯速度上来说，memcache的性能要比redis要更好。机制:memcache的内存分布如下所示，其实类似于linux文件系统，存在一定的内存浪费 而关于redis的内存分配则是根据基础结构来定的，浪费较少，不过这样的分配容易出现内存碎片问题，官方文档资源则详细得多，我这里直接粘一下好了，一共4点 当key被删除的时候，redis不会立刻释放内存，如果使用了5G内存，然后释放了2G，那么实际上的占用依然会是5G 基于第一点，需要预见到实际的redis占用，如果高峰期可能使用到10G，那么就需要提前预备10G的内存（貌似是废话） 如果申请了5G之后，释放了2G，之后又需要使用内存，那么redis会基本上会重复使用这2G的资源（貌似也是废话） 这样的话，碎片率的当 峰值/平时值 比率较高的时候，碎片率会比较高参考部分：memory-optimization 3. 数据持久化memcache简单粗暴，直接不支持redis支持，两种模式：rdb快照&amp;AOF文件 4. 集群化管理memcache本身对于集群化是无感知的，就是说，可以启动多个memcache节点，完了在客户端通过算法，将数据hash到各个节点上，通过client端的处理来做一个集群![memcacheCluster]{memcacheCluster.png}redis的集群则可以直接在服务端做处理，![redisCluster]{redisCluster.png}","categories":[{"name":"技术","slug":"技术","permalink":"http://kevingeek.github.io/categories/技术/"}],"tags":[{"name":"In-Memory Data Storage Systems","slug":"In-Memory-Data-Storage-Systems","permalink":"http://kevingeek.github.io/tags/In-Memory-Data-Storage-Systems/"}]},{"title":"苦命管家之巧解草莓风波","slug":"Stawberry","date":"2017-02-19T10:24:50.000Z","updated":"2020-04-09T04:19:33.058Z","comments":true,"path":"2017/02/19/Stawberry/","link":"","permalink":"http://kevingeek.github.io/2017/02/19/Stawberry/","excerpt":"阿哲是村东边的大户，他有一个特别厉害的管家，能说会道，智商超人，说到草莓风波…","text":"阿哲是村东边的大户，他有一个特别厉害的管家，能说会道，智商超人，说到草莓风波… 事起老爷平日没啥爱好，年前下苏杭时候碰巧尝了一次草莓，至此每日念念不忘，招来管家… 原来是老爷嘴馋了 嘴馋也有讲究，不是胡吃海喝，咱们要持续性发展… 草莓这物件，这年代也没冰箱什么的，最新鲜的就是每日采摘，老爷做的长远打算，每日一醒就对草莓心心念念，所以啊，就想越早越好，晚来一点也没关系，但是必须是今天摘的才行，但是一天都没吃到好草莓，我可是要发飙哦！ 还有，这草莓虽好，但是也不能贪杯哦…啊呸，不能多吃，每日一袋是为最好，之后来的，就把他们退掉吧！ 老爷想要的是什么对于老爷的想法，管家自然是摸得透彻，稍作盘算，就知道老爷想的是啥 每天都需要消耗一批草莓(尽最大努力) 每天仅吃一批草莓 只吃当日最新鲜的、质量过关的草莓，至于是谁提供的并不重要 如果有多余的或者不合格的草莓，则需要把他们处理掉(退货) 召集商家任务吩咐下去，让管家一手操办，老板提出了需求，那管家就只能跑跑腿了～ 要拿到草莓，那得首先联系一下草莓供应商是个什么情况 几日之后，很快就有了消息，这几家供应商，因为草莓属于现摘，每日的情况都不一样，供应商每天送来都货物质量也都参差不齐，需要管家一一验过如果货物质量不行，那么就只能退货啦，又或者我们老爷当日只能吃过草莓了，那么抱歉，你这批货我只能退啦，要是你来的时候，管家还在验上家的货，那你可以碰碰运气，万一上家的货物不过关呢，是吧～ 简而言之，市场竞争真是激烈呀！ 那么提炼一下： 不保证每日都有货物 不保证货物的质量 不保证到货时间 接受退货 供应商在货物送到之前，并不知晓老爷今日是否已经享用了草莓 嗯，任性的供应商提供的服务还真是不怎么可靠啊，但是这总难不住聪明的管家，咋一看，虽然每一家货物提供商并不能提供完全可靠的服务，但是我多喊几家一起上，那么老爷的需求还是可以尽量满足的嘛，想到这里，管家就被自己的聪明才智锁折服了，心里还有点小激动呢 (ಡωಡ)hiahiahia 心中一阵盘算之后，通知供应商们召集到院中开了一次集体会议…. 一个月黑风高的夜晚众商家，今日将大家召集到此，是为了通知各商家之后咱们的统一供货方式，一方面尽量保证老爷的要求，一方面呢，也是和大家打个招呼，咱们以后就按照这个法子来，互通有无嘛 之后每日，若各位货物到后，可将货物先置放于院中，然后由知晓我，待我来对货物进行验收，验收通过之后，向你发放当日款项。若通知我时，我已找到一批新鲜的货物，那么你货的新鲜程度不如上家，自然是输了，那么我就无法给你款项，只能将货退还给你。若我还在验货，那你可以再等等，若之前的货物不合格，那么你可以等等，若上家的货物不符合老爷的要求，那么我就可以来验你的货啦～ 各商家见管家提出如此妥善的注意，事少，也不用和别家伤和气，一切买卖全凭本事，一个一个也摩拳擦掌，纷纷表示赞同 单机版一段时日之后，老爷如愿吃上了想要的草莓🍓，管家也将此方法记录了下来，以便改进与学习 :) 商家p1、p2属于集合P(Provider)，商家提供的服务都是同质的，可以归为一类，分别为 送货 deliver 验货 validate 退货 takeBack 而管家g(governor)的状态分为几种 尚未验货 available 正在验货 validating 验货结束 unavailable 那么商家所执行的步骤可以用如下伪代码表示： public class ProviderDeliver { public void dailyWork(Provider p, Governor g){} p.deliver(); if (g.unavailable()) { p.takeBack(); return ; } while (g.validating()) { // simply wait } if (g.available()) { p.validate(); } else { p.takeBack(); } } 分布式版哎呀，老爷一高兴，赏金给得特别高，各路商家接踵而至，管家要忙不过来了，于是吩咐下去几个家丁，分别接待商户，检查依然由管家亲自操作，但商户无需等待，仅需要将货物放在府中，退货由家丁完成，而商户也不直接与管家接触，由家丁负责商家和管家之间的沟通，管家通过府邸中的旗帜表示自己目前正在验货、休息、验货完毕 那么整体的流程作一下简单转换，对商户来说，流程更加简单 /** * * Created by kevin on 20/02/2017. */ public class Strawberry { static AtomicInteger errorCount = new AtomicInteger(0); static AtomicInteger takeBackCount = new AtomicInteger(0); static AtomicInteger consumedCount = new AtomicInteger(0); static AtomicInteger acceptedCount = new AtomicInteger(0); static Random r = new Random(); static class ProviderDeliver2 { private Provider p; ProviderDeliver2(String name) { this.p = new Provider(name); } void dailyWork(int day) { Merchandise m = p.deliver(); // 运送货物 Worker worker = Worker.of(this, day); // 随便找个家丁，并把货物交给他 worker.process(m); // 家丁来处理货物 } void takeBack(Merchandise m) { int res = m.getTime().incrementAndGet(); if (res == 1) { takeBackCount.incrementAndGet(); } else if (res > 1) { System.out.println(\"fail! operate \" + res ); errorCount.incrementAndGet(); } } } static class Worker { private Governor g; private ProviderDeliver2 pd2; Worker(ProviderDeliver2 pd2, Governor g) { this.pd2 = pd2; this.g = g; } static Worker of(ProviderDeliver2 pd2, int day) { return new Worker(pd2, Governor.getInstance(day)); } void process(Merchandise m) { g.validate(this, m); } void takeBack(Merchandise m) { pd2.takeBack(m); } } static class Governor { private AtomicBoolean available = new AtomicBoolean(true); private AtomicBoolean validating = new AtomicBoolean(false); private Queue queue = Queues.newConcurrentLinkedQueue(); private int date; private static ConcurrentHashMap MAP = new ConcurrentHashMap(); static Governor getInstance(int day) { return MAP.computeIfAbsent(day, Governor::new); } boolean available() { return available.get(); } private Governor(int date) { this.date = date; } void validate(Worker worker, Merchandise m) { try { if (!available()) { worker.takeBack(m); return; } this.addMerchandise(m); if (!validating.compareAndSet(false, true)) { return; } if (!available()) { cleanAll(worker); return; } while (!queue.isEmpty()) { Merchandise item = queue.poll(); if (available() && item.isGood()) { available.set(false); acceptedCount.incrementAndGet(); } else { worker.takeBack(item); } } validating.set(false); } finally { consumedCount.incrementAndGet(); } } private void cleanAll(Worker worker) { while (!queue.isEmpty()) { Merchandise item = queue.poll(); worker.takeBack(item); } } void addMerchandise(Merchandise m) { queue.add(m); } } public static class Provider { private String name; Provider(String name) { this.name = name; } Merchandise deliver() { return new Merchandise(this.name + System.nanoTime()); } } static class Merchandise { private String name; private AtomicInteger time = new AtomicInteger(0); private long quality = r.nextInt(100); AtomicInteger getTime() { return time; } Merchandise(String name) { this.name = name; } @Override public boolean equals(Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Merchandise that = (Merchandise) o; return name != null ? name.equals(that.name) : that.name == null; } @Override public int hashCode() { return name != null ? name.hashCode() : 0; } boolean isGood() { // return true; return quality < 80; } } public static void main(String[] args) throws InterruptedException { // 模仿5个商家，连续提供500日的情况 int k = 0; for (int day = 0; day < 500; day++) { int tmpDay = day; for (int i = 0; i < 5; i++) { new Thread(() -> new ProviderDeliver2(String.valueOf(tmpDay)).dailyWork(tmpDay)).start(); k++; } } while (k != consumedCount.get()) { Thread.sleep(10); } System.out.println(\"done\"); System.out.println(errorCount.get()); //0 System.out.println(takeBackCount.get()); // System.out.println(acceptedCount.get()); // System.out.println(consumedCount.get()); // } }","categories":[{"name":"日常","slug":"日常","permalink":"http://kevingeek.github.io/categories/日常/"}],"tags":[{"name":"Algorithm","slug":"Algorithm","permalink":"http://kevingeek.github.io/tags/Algorithm/"},{"name":"分布式","slug":"分布式","permalink":"http://kevingeek.github.io/tags/分布式/"}]},{"title":"限流之RateLimiter","slug":"RateLimiter","date":"2016-10-24T12:59:25.000Z","updated":"2020-04-09T04:19:33.057Z","comments":true,"path":"2016/10/24/RateLimiter/","link":"","permalink":"http://kevingeek.github.io/2016/10/24/RateLimiter/","excerpt":"高并发三板斧,缓存、降级和限流","text":"高并发三板斧,缓存、降级和限流 老话说得好，要想服务器耍得好，三板斧不能少，今天我们就来看看其中的一板斧–‘限流’ 什么是限流 简单明了的说，在系统当中，有一些第三方应用具有并行能力上限(比如某些垄断行业提供的接口)，你多请求了直接给你返回错误码，还有一些具体的服务，比如秒杀等，仅允许一定的速率来访问特定的资源，在这些应用场景中，就需要用到限流来完成这些事情。 一些通常的case，比如说限制总并发数(DB)，瞬间并发数(Nginx limit_conn)，限制平均速率(RateLimiter)等。而我们今天所要具体讨论的，就是限制平均速率的方法。 两大算法 当然，在此之前我们先来讨论一下限流的两大算法：漏桶、令牌桶。 漏桶 令牌桶 ReteLimiter好啦,那就让我们来看一下令牌桶算法的具体应用,强大的guava包的RateLimiter已经实现了限流,使用的是令牌桶算法,并且可以允许一定程度的请求激增,看起来是非常好的东西~简单来说,看注释上来说,是通过时间的换算来等价于令牌的存储的,具体的实现方法,看具体的代码实现吧~ /* * Copyright (C) 2012 The Guava Authors * * Licensed under the Apache License, Version 2.0 (the \"License\"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at 屌屌的，先说明一下是基于Apache2的哦～ * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.google.common.util.concurrent; import com.google.common.annotations.Beta; import com.google.common.annotations.VisibleForTesting; import com.google.common.base.Preconditions; import com.google.common.base.Ticker; import java.util.concurrent.TimeUnit; import javax.annotation.concurrent.ThreadSafe; /** * A rate limiter. Conceptually, a rate limiter distributes permits at a * configurable rate. Each {@link #acquire()} blocks if necessary until a permit is * available, and then takes it. Once acquired, permits need not be released. 字面意思上来说，rateLimiter当然是按照一个给定的速率来进行派发令牌啦～ 执行acquire()方法，会一直阻塞，直到有一个令牌是可用的，然后获得这个令牌，一旦令牌被获得! 令牌是不需要被 `释放` 的! * Rate limiters are often used to restrict the rate at which some * physical or logical resource is accessed. This is in contrast to {@link * java.util.concurrent.Semaphore} which restricts the number of concurrent * accesses instead of the rate (note though that concurrency and rate are closely related, * e.g. see Little's Law). RateLimiter 常常被用来限制某些资源的访问速率。 这和Semaphore不同，Semaphore是用来限制 并发数而不是速率，这两者还是有不同的。 * A {@code RateLimiter} is defined primarily by the rate at which permits * are issued. Absent additional configuration, permits will be distributed at a * fixed rate, defined in terms of permits per second. Permits will be distributed * smoothly, with the delay between individual permits being adjusted to ensure * that the configured rate is maintained. 如果没有额外的配置，令牌会以固定的速率派发，这个速率以每秒为单位计算。 令牌将会以平滑的速率派发，单位令牌之间的间隔会被良好调配以保障之前设定好的速率。 * * It is possible to configure a {@code RateLimiter} to have a warmup * period during which time the permits issued each second steadily increases until * it hits the stable rate. 通过配置，也可以使用一个预热的阶段，在这个阶段中每秒分发的令牌数将会递增直到达到边界值为止 * * As an example, imagine that we have a list of tasks to execute, but we don't want to * submit more than 2 per second: 一个简单的例子，有一个任务队列需要执行，但是我们不想每秒同时执行的任务超过2个，那么可以这样写 * {@code * final RateLimiter rateLimiter = RateLimiter.create(2.0); // rate is \"2 permits per second\" * void submitTasks(List tasks, Executor executor) { * for (Runnable task : tasks) { * rateLimiter.acquire(); // may wait * executor.execute(task); * } * } *} * * As another example, imagine that we produce a stream of data, and we want to cap it * at 5kb per second. This could be accomplished by requiring a permit per byte, and specifying * a rate of 5000 permits per second: 另一个例子就是，想象一下正在处理一个数据流，然后我们想每秒处理5kb。这里的处理方式，为每个byte分配一个令牌， 并且指定每秒有5000个令牌。 * {@code * final RateLimiter rateLimiter = RateLimiter.create(5000.0); // rate = 5000 permits per second * void submitPacket(byte[] packet) { * rateLimiter.acquire(packet.length); * networkService.send(packet); * } *} * * It is important to note that the number of permits requested never * affect the throttling of the request itself (an invocation to {@code acquire(1)} * and an invocation to {@code acquire(1000)} will result in exactly the same throttling, if any), * but it affects the throttling of the next request. I.e., if an expensive task * arrives at an idle RateLimiter, it will be granted immediately, but it is the next * request that will experience extra throttling, thus paying for the cost of the expensive * task. 作者提到了很重要的一点，当前请求的令牌数量并不会阻止当前的请求，acquire(1)和acquire(1000)会导致相同的结果， 如果当前的请求消耗了特别多的令牌，那么是由“下一个请求\"来偿还当前这个请求所耗费的令牌。 这里有点绕，具体还是看代码吧 * * Note: {@code RateLimiter} does not provide fairness guarantees. 嗯...这就是不公平的，就像这个世界一样 =。= face and embrace it * * @author Dimitris Andreou * @since 13.0 */ // TODO(user): switch to nano precision. A natural unit of cost is \"bytes\", and a micro precision // would mean a maximum rate of \"1MB/s\", which might be small in some cases. @ThreadSafe @Beta // wow， 原来这玩意还只是个Beta版本呀～ public abstract class RateLimiter { /* * How is the RateLimiter designed, and why? * * The primary feature of a RateLimiter is its \"stable rate\", the maximum rate that * is should allow at normal conditions. This is enforced by \"throttling\" incoming * requests as needed, i.e. compute, for an incoming request, the appropriate throttle time, * and make the calling thread wait as much. 对于RateLimiter最主要的特性就是“稳定的速率”，在通常情况下，允许以最高的速率进行运作。 后面的不知道怎么翻译 * * The simplest way to maintain a rate of QPS is to keep the timestamp of the last * granted request, and ensure that (1/QPS) seconds have elapsed since then. For example, * for a rate of QPS=5 (5 tokens per second), if we ensure that a request isn't granted * earlier than 200ms after the the last one, then we achieve the intended rate. * If a request comes and the last request was granted only 100ms ago, then we wait for * another 100ms. At this rate, serving 15 fresh permits (i.e. for an acquire(15) request) * naturally takes 3 seconds. 最简单的控制QPS的办法,就是控制时间戳嘛,只要保证自从上一次发送令牌到现在已经经过了(1/QPS)秒即可,那么 这样就保证了基本的QPS. * It is important to realize that such a RateLimiter has a very superficial memory * of the past: it only remembers the last request. What if the RateLimiter was unused for * a long period of time, then a request arrived and was immediately granted? * This RateLimiter would immediately forget about that past underutilization. This may * result in either underutilization or overflow, depending on the real world consequences * of not using the expected rate. 上述做法虽然简单粗暴,但是有一个很重要的一点,就是它“对于过去的认识并不充分”--它仅记住了上一次的请求, 如果RateLimiter很久不被使用，新来了一个请求,并且这个请求很快会获得指令,那么它机会\"忘记\"掉之前的低使用率, 这可能会导致一些问题,具体取决于具体的场景. * Past underutilization could mean that excess resources are available. Then, the RateLimiter * should speed up for a while, to take advantage of these resources. This is important * when the rate is applied to networking (limiting bandwidth), where past underutilization * typically translates to \"almost empty buffers\", which can be filled immediately. 过去的低使用率意味着有剩余的可用资源,所以RateLimiter可以提速(??? 这里不清楚应该怎么翻译)来使用这些资源, * On the other hand, past underutilization could mean that \"the server responsible for * handling the request has become less ready for future requests\", i.e. its caches become * stale, and requests become more likely to trigger expensive operations (a more extreme * case of this example is when a server has just booted, and it is mostly busy with getting * itself up to speed). 另个方面讲,低使用率意味着处理这些请求的服务有可能还没有准备好使用这些请求,比如说当服务使用到cache时, 那么在长时间的间隔之后的突然请求,有可能会造成cache的大量miss,更极端的请求是当服务刚启动时. * To deal with such scenarios, we add an extra dimension, that of \"past underutilization\", * modeled by \"storedPermits\" variable. This variable is zero when there is no * underutilization, and it can grow up to maxStoredPermits, for sufficiently large * underutilization. So, the requested permits, by an invocation acquire(permits), * are served from: * - stored permits (if available) * - fresh permits (for any remaining permits) 作者使用了一个额外的维度来描述过去的低使用率, storedPermits 当新请求令牌时,令牌从stored permits和fresh permits两个地方获得 * How this works is best explained with an example: * * For a RateLimiter that produces 1 token per second, every second * that goes by with the RateLimiter being unused, we increase storedPermits by 1. * Say we leave the RateLimiter unused for 10 seconds (i.e., we expected a request at time * X, but we are at time X + 10 seconds before a request actually arrives; this is * also related to the point made in the last paragraph), thus storedPermits * becomes 10.0 (assuming maxStoredPermits >= 10.0). At that point, a request of acquire(3) * arrives. We serve this request out of storedPermits, and reduce that to 7.0 (how this is * translated to throttling time is discussed later). Immediately after, assume that an * acquire(10) request arriving. We serve the request partly from storedPermits, * using all the remaining 7.0 permits, and the remaining 3.0, we serve them by fresh permits * produced by the rate limiter. storedPermits其实是一个预备的库存的意思,如果其中还有令牌预存,就直接取,如果不够的话,不足的部分用fresh permits来弥补 当然,作者将这些补偿的公式都转换为时间上的计算,计算方式后面再看 * We already know how much time it takes to serve 3 fresh permits: if the rate is * \"1 token per second\", then this will take 3 seconds. But what does it mean to serve 7 * stored permits? As explained above, there is no unique answer. If we are primarily * interested to deal with underutilization, then we want stored permits to be given out * /faster/ than fresh ones, because underutilization = free resources for the taking. * If we are primarily interested to deal with overflow, then stored permits could * be given out /slower/ than fresh ones. Thus, we require a (different in each case) * function that translates storedPermits to throtting time. 其实新请求3个令牌的时间是容易计算的,那么问题就在于如何表示\"提供7个stored permits\"? 作者说, 1:如果要应对的低使用率,那么在提供stored permits的时候就需要比fresh permits要\"快\"一些,因为 实际上stored permits就意味着是\"闲置的资源\", 2:如果要应对的是过高使用率,那么stored permits就需要慢一些 所以作者require了一个function来将storePermits转化为throtting time OK,下面就是算法描述,看不懂,先看代码~ * This role is played by storedPermitsToWaitTime(double storedPermits, double permitsToTake). * The underlying model is a continuous function mapping storedPermits * (from 0.0 to maxStoredPermits) onto the 1/rate (i.e. intervals) that is effective at the given * storedPermits. \"storedPermits\" essentially measure unused time; we spend unused time * buying/storing permits. Rate is \"permits / time\", thus \"1 / rate = time / permits\". * Thus, \"1/rate\" (time / permits) times \"permits\" gives time, i.e., integrals on this * function (which is what storedPermitsToWaitTime() computes) correspond to minimum intervals * between subsequent requests, for the specified number of requested permits. * * Here is an example of storedPermitsToWaitTime: * If storedPermits == 10.0, and we want 3 permits, we take them from storedPermits, * reducing them to 7.0, and compute the throttling for these as a call to * storedPermitsToWaitTime(storedPermits = 10.0, permitsToTake = 3.0), which will * evaluate the integral of the function from 7.0 to 10.0. * * Using integrals guarantees that the effect of a single acquire(3) is equivalent * to { acquire(1); acquire(1); acquire(1); }, or { acquire(2); acquire(1); }, etc, * since the integral of the function in [7.0, 10.0] is equivalent to the sum of the * integrals of [7.0, 8.0], [8.0, 9.0], [9.0, 10.0] (and so on), no matter * what the function is. This guarantees that we handle correctly requests of varying weight * (permits), /no matter/ what the actual function is - so we can tweak the latter freely. * (The only requirement, obviously, is that we can compute its integrals). * * Note well that if, for this function, we chose a horizontal line, at height of exactly * (1/QPS), then the effect of the function is non-existent: we serve storedPermits at * exactly the same cost as fresh ones (1/QPS is the cost for each). We use this trick later. * * If we pick a function that goes /below/ that horizontal line, it means that we reduce * the area of the function, thus time. Thus, the RateLimiter becomes /faster/ after a * period of underutilization. If, on the other hand, we pick a function that * goes /above/ that horizontal line, then it means that the area (time) is increased, * thus storedPermits are more costly than fresh permits, thus the RateLimiter becomes * /slower/ after a period of underutilization. * * Last, but not least: consider a RateLimiter with rate of 1 permit per second, currently * completely unused, and an expensive acquire(100) request comes. It would be nonsensical * to just wait for 100 seconds, and /then/ start the actual task. Why wait without doing * anything? A much better approach is to /allow/ the request right away (as if it was an * acquire(1) request instead), and postpone /subsequent/ requests as needed. In this version, * we allow starting the task immediately, and postpone by 100 seconds future requests, * thus we allow for work to get done in the meantime instead of waiting idly. * * This has important consequences: it means that the RateLimiter doesn't remember the time * of the _last_ request, but it remembers the (expected) time of the _next_ request. This * also enables us to tell immediately (see tryAcquire(timeout)) whether a particular * timeout is enough to get us to the point of the next scheduling time, since we always * maintain that. And what we mean by \"an unused RateLimiter\" is also defined by that * notion: when we observe that the \"expected arrival time of the next request\" is actually * in the past, then the difference (now - past) is the amount of time that the RateLimiter * was formally unused, and it is that amount of time which we translate to storedPermits. * (We increase storedPermits with the amount of permits that would have been produced * in that idle time). So, if rate == 1 permit per second, and arrivals come exactly * one second after the previous, then storedPermits is _never_ increased -- we would only * increase it for arrivals _later_ than the expected one second. */ /** * Creates a {@code RateLimiter} with the specified stable throughput, given as * \"permits per second\" (commonly referred to as QPS, queries per second). * * The returned {@code RateLimiter} ensures that on average no more than {@code * permitsPerSecond} are issued during any given second, with sustained requests * being smoothly spread over each second. When the incoming request rate exceeds * {@code permitsPerSecond} the rate limiter will release one permit every {@code * (1.0 / permitsPerSecond)} seconds. When the rate limiter is unused, * bursts of up to {@code permitsPerSecond} permits will be allowed, with subsequent * requests being smoothly limited at the stable rate of {@code permitsPerSecond}. RateLimiter保证了 * @param permitsPerSecond the rate of the returned {@code RateLimiter}, measured in * how many permits become available per second. */ // TODO(user): \"This is equivalent to // {@code createWithCapacity(permitsPerSecond, 1, TimeUnit.SECONDS)}\". public static RateLimiter create(double permitsPerSecond) { /* * The default RateLimiter configuration can save the unused permits of up to one second. * This is to avoid unnecessary stalls in situations like this: A RateLimiter of 1qps, * and 4 threads, all calling acquire() at these moments: * * T0 at 0 seconds * T1 at 1.05 seconds * T2 at 2 seconds * T3 at 3 seconds * * Due to the slight delay of T1, T2 would have to sleep till 2.05 seconds, * and T3 would also have to sleep till 3.05 seconds. */ return create(SleepingTicker.SYSTEM_TICKER, permitsPerSecond); } @VisibleForTesting static RateLimiter create(SleepingTicker ticker, double permitsPerSecond) { RateLimiter rateLimiter = new Bursty(ticker, 1.0 /* maxBurstSeconds */); rateLimiter.setRate(permitsPerSecond); return rateLimiter; } /** * Creates a {@code RateLimiter} with the specified stable throughput, given as * \"permits per second\" (commonly referred to as QPS, queries per second), and a * warmup period, during which the {@code RateLimiter} smoothly ramps up its rate, * until it reaches its maximum rate at the end of the period (as long as there are enough * requests to saturate it). Similarly, if the {@code RateLimiter} is left unused for * a duration of {@code warmupPeriod}, it will gradually return to its \"cold\" state, * i.e. it will go through the same warming up process as when it was first created. * * The returned {@code RateLimiter} is intended for cases where the resource that actually * fulfills the requests (e.g., a remote server) needs \"warmup\" time, rather than * being immediately accessed at the stable (maximum) rate. * * The returned {@code RateLimiter} starts in a \"cold\" state (i.e. the warmup period * will follow), and if it is left unused for long enough, it will return to that state. * * @param permitsPerSecond the rate of the returned {@code RateLimiter}, measured in * how many permits become available per second * @param warmupPeriod the duration of the period where the {@code RateLimiter} ramps up its * rate, before reaching its stable (maximum) rate * @param unit the time unit of the warmupPeriod argument */ public static RateLimiter create(double permitsPerSecond, long warmupPeriod, TimeUnit unit) { return create(SleepingTicker.SYSTEM_TICKER, permitsPerSecond, warmupPeriod, unit); } @VisibleForTesting static RateLimiter create( SleepingTicker ticker, double permitsPerSecond, long warmupPeriod, TimeUnit unit) { RateLimiter rateLimiter = new WarmingUp(ticker, warmupPeriod, unit); rateLimiter.setRate(permitsPerSecond); return rateLimiter; } @VisibleForTesting static RateLimiter createWithCapacity( SleepingTicker ticker, double permitsPerSecond, long maxBurstBuildup, TimeUnit unit) { double maxBurstSeconds = unit.toNanos(maxBurstBuildup) / 1E+9; Bursty rateLimiter = new Bursty(ticker, maxBurstSeconds); rateLimiter.setRate(permitsPerSecond); return rateLimiter; } /** * The underlying timer; used both to measure elapsed time and sleep as necessary. A separate * object to facilitate testing. */ private final SleepingTicker ticker; /** * The timestamp when the RateLimiter was created; used to avoid possible overflow/time-wrapping * errors. */ private final long offsetNanos; /** * The currently stored permits. */ double storedPermits; /** * The maximum number of stored permits. */ double maxPermits; /** * The interval between two unit requests, at our stable rate. E.g., a stable rate of 5 permits * per second has a stable interval of 200ms. */ volatile double stableIntervalMicros; private final Object mutex = new Object(); /** * The time when the next request (no matter its size) will be granted. After granting a request, * this is pushed further in the future. Large requests push this further than small requests. */ private long nextFreeTicketMicros = 0L; // could be either in the past or future private RateLimiter(SleepingTicker ticker) { this.ticker = ticker; this.offsetNanos = ticker.read(); } /** * Updates the stable rate of this {@code RateLimiter}, that is, the * {@code permitsPerSecond} argument provided in the factory method that * constructed the {@code RateLimiter}. Currently throttled threads will not * be awakened as a result of this invocation, thus they do not observe the new rate; * only subsequent requests will. * * Note though that, since each request repays (by waiting, if necessary) the cost * of the previous request, this means that the very next request * after an invocation to {@code setRate} will not be affected by the new rate; * it will pay the cost of the previous request, which is in terms of the previous rate. * * The behavior of the {@code RateLimiter} is not modified in any other way, * e.g. if the {@code RateLimiter} was configured with a warmup period of 20 seconds, * it still has a warmup period of 20 seconds after this method invocation. * * @param permitsPerSecond the new stable rate of this {@code RateLimiter}. */ public final void setRate(double permitsPerSecond) { Preconditions.checkArgument(permitsPerSecond > 0.0 && !Double.isNaN(permitsPerSecond), \"rate must be positive\"); synchronized (mutex) { resync(readSafeMicros()); double stableIntervalMicros = TimeUnit.SECONDS.toMicros(1L) / permitsPerSecond; this.stableIntervalMicros = stableIntervalMicros; doSetRate(permitsPerSecond, stableIntervalMicros); } } abstract void doSetRate(double permitsPerSecond, double stableIntervalMicros); /** * Returns the stable rate (as {@code permits per seconds}) with which this * {@code RateLimiter} is configured with. The initial value of this is the same as * the {@code permitsPerSecond} argument passed in the factory method that produced * this {@code RateLimiter}, and it is only updated after invocations * to {@linkplain #setRate}. */ public final double getRate() { return TimeUnit.SECONDS.toMicros(1L) / stableIntervalMicros; } /** * Acquires a permit from this {@code RateLimiter}, blocking until the request can be granted. * * This method is equivalent to {@code acquire(1)}. */ public void acquire() { acquire(1); } /** * Acquires the given number of permits from this {@code RateLimiter}, blocking until the * request be granted. * * @param permits the number of permits to acquire */ public void acquire(int permits) { checkPermits(permits); long microsToWait; synchronized (mutex) { microsToWait = reserveNextTicket(permits, readSafeMicros()); } ticker.sleepMicrosUninterruptibly(microsToWait); } /** * Acquires a permit from this {@code RateLimiter} if it can be obtained * without exceeding the specified {@code timeout}, or returns {@code false} * immediately (without waiting) if the permit would not have been granted * before the timeout expired. * * This method is equivalent to {@code tryAcquire(1, timeout, unit)}. * * @param timeout the maximum time to wait for the permit * @param unit the time unit of the timeout argument * @return {@code true} if the permit was acquired, {@code false} otherwise */ public boolean tryAcquire(long timeout, TimeUnit unit) { return tryAcquire(1, timeout, unit); } /** * Acquires permits from this {@link RateLimiter} if it can be acquired immediately without delay. * * * This method is equivalent to {@code tryAcquire(permits, 0, anyUnit)}. * * @param permits the number of permits to acquire * @return {@code true} if the permits were acquired, {@code false} otherwise * @since 14.0 */ public boolean tryAcquire(int permits) { return tryAcquire(permits, 0, TimeUnit.MICROSECONDS); } /** * Acquires a permit from this {@link RateLimiter} if it can be acquired immediately without * delay. * * * This method is equivalent to {@code tryAcquire(1)}. * * @return {@code true} if the permit was acquired, {@code false} otherwise * @since 14.0 */ public boolean tryAcquire() { return tryAcquire(1, 0, TimeUnit.MICROSECONDS); } /** * Acquires the given number of permits from this {@code RateLimiter} if it can be obtained * without exceeding the specified {@code timeout}, or returns {@code false} * immediately (without waiting) if the permits would not have been granted * before the timeout expired. * * @param permits the number of permits to acquire * @param timeout the maximum time to wait for the permits * @param unit the time unit of the timeout argument * @return {@code true} if the permits were acquired, {@code false} otherwise */ public boolean tryAcquire(int permits, long timeout, TimeUnit unit) { long timeoutMicros = unit.toMicros(timeout); checkPermits(permits); long microsToWait; synchronized (mutex) { long nowMicros = readSafeMicros(); if (nextFreeTicketMicros > nowMicros + timeoutMicros) { return false; } else { microsToWait = reserveNextTicket(permits, nowMicros); } } ticker.sleepMicrosUninterruptibly(microsToWait); return true; } private static void checkPermits(int permits) { Preconditions.checkArgument(permits > 0, \"Requested permits must be positive\"); } /** * Reserves next ticket and returns the wait time that the caller must wait for. */ private long reserveNextTicket(double requiredPermits, long nowMicros) { resync(nowMicros); long microsToNextFreeTicket = nextFreeTicketMicros - nowMicros; double storedPermitsToSpend = Math.min(requiredPermits, this.storedPermits); double freshPermits = requiredPermits - storedPermitsToSpend; long waitMicros = storedPermitsToWaitTime(this.storedPermits, storedPermitsToSpend) + (long) (freshPermits * stableIntervalMicros); this.nextFreeTicketMicros = nextFreeTicketMicros + waitMicros; this.storedPermits -= storedPermitsToSpend; return microsToNextFreeTicket; } /** * Translates a specified portion of our currently stored permits which we want to * spend/acquire, into a throttling time. Conceptually, this evaluates the integral * of the underlying function we use, for the range of * [(storedPermits - permitsToTake), storedPermits]. * * This always holds: {@code 0","categories":[{"name":"Java","slug":"Java","permalink":"http://kevingeek.github.io/categories/Java/"}],"tags":[{"name":"RateLimiter","slug":"RateLimiter","permalink":"http://kevingeek.github.io/tags/RateLimiter/"},{"name":"Server","slug":"Server","permalink":"http://kevingeek.github.io/tags/Server/"}]},{"title":"HashMap源码解析","slug":"HashMap源码解析","date":"2016-08-02T09:35:00.000Z","updated":"2020-04-09T04:19:33.057Z","comments":true,"path":"2016/08/02/HashMap源码解析/","link":"","permalink":"http://kevingeek.github.io/2016/08/02/HashMap源码解析/","excerpt":"一坑未平，一坑又起，今天我们来看一下HashMapHashMap继承自AbstractMap，实现Map接口，是一个标准的Map实现","text":"一坑未平，一坑又起，今天我们来看一下HashMapHashMap继承自AbstractMap，实现Map接口，是一个标准的Map实现 初始化HashMap一个参数为初始大小值， 一个为填充因子，可以发现，在构造函数里面除了基本的赋值外，并没有做数据初始化的操作，而那个init()则是个幌子= =，正宗的啥也没干啊 /** * Constructs an empty HashMap with the specified initial * capacity and load factor. * * @param initialCapacity 初始大小 * @param loadFactor 填充因子 * @throws IllegalArgumentException if the initial capacity is negative * or the load factor is nonpositive */ public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity < 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity > MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor = toSize int capacity = roundUpToPowerOf2(toSize); //这里很精妙的设置了capacity threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); table = new Entry[capacity]; initHashSeedAsNeeded(capacity); // 设置哈希种子 We defer initialization until we really need it. } 在roundUpTOPowerOf2方法里面返回的是2的N次方，假设为X，N取使得X大于toSize的集合中的最小值，例如 roundUpToPowerOf2(31) = 32 roundUpToPowerOf2(60) = 64 添加元素put重头戏put方法，添加元素如上图所说，We defer initialization until we really need it., 那么很容易联想到，inflateTable函数其实是在put方法里面会被调用，因为这时候才really need it嘛。 /** * Associates the specified value with the specified key in this map. * If the map previously contained a mapping for the key, the old * value is replaced. * * @param key key with which the specified value is to be associated * @param value value to be associated with the specified key * @return the previous value associated with key, or * null if there was no mapping for key. * (A null return can also indicate that the map * previously associated null with key.) */ public V put(K key, V value) { if (table == EMPTY_TABLE) { inflateTable(threshold); //如果是空Map的话，就做初始化操作 } if (key == null) return putForNullKey(value); // 这里对null值做了单独的处理 int hash = hash(key); int i = indexFor(hash, table.length); // 这个indexFor巧妙利用了table的Length for (Entry e = table[i]; e != null; e = e.next) { Object k; // 如果hash值一样(键冲突)，并key是真的一样的话 // 则用新的value覆盖老value，返回老value if (e.hash == hash && ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++; // 如果没有出现key完全相同的情况(例如hash值不同，或者只是hash冲突了) // 添加新的Entry，这个addEntry的部分需要好好看看 addEntry(hash, key, value, i); return null; } put-indexFor由给定的hash值，返回对应的哈希桶下标直接使用length-1和hash值进行与操作， 因为length是2的次方，所以length -1所有位上都是1，直接与操作可以迅速获得对应的Index值 /** * Returns index for hash code h. */ static int indexFor(int h, int length) { // assert Integer.bitCount(length) == 1 : \"length must be a non-zero power of 2\"; return h & (length-1); } put-addEntry给将数据添加到table中，如果有必要，new一个新的table :) /** * Adds a new entry with the specified key, value and hash code to * the specified bucket. It is the responsibility of this * method to resize the table if appropriate. * * Subclass overrides this to alter the behavior of put method. */ void addEntry(int hash, K key, V value, int bucketIndex) { // 如果当前Map的size已经大于阈值，并且当前这个哈系桶也已经被实例化过的话 // 则需要进行长度填充，新长度为原长度的2倍 if ((size >= threshold) && (null != table[bucketIndex])) { resize(2 * table.length); // resize的开销比较大，我们一会看一下 hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length);// 获得哈希桶的下标 } createEntry(hash, key, value, bucketIndex); } put-addEntry-resizeresize，对table进行扩容需要完成几个步骤 开辟新数组 将oldTable中的值全部映射newTable中 如果有必要的话，重新生成hashSeed(这块我没看懂，欢迎大神指教) /** * Rehashes the contents of this map into a new array with a * larger capacity. This method is called automatically when the * number of keys in this map reaches its threshold. * * If current capacity is MAXIMUM_CAPACITY, this method does not * resize the map, but sets threshold to Integer.MAX_VALUE. * This has the effect of preventing future calls. * * @param newCapacity the new capacity, MUST be a power of two; * must be greater than current capacity unless current * capacity is MAXIMUM_CAPACITY (in which case value * is irrelevant). */ void resize(int newCapacity) { Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return; } Entry[] newTable = new Entry[newCapacity]; transfer(newTable, initHashSeedAsNeeded(newCapacity)); // 转移元素 table = newTable; //将table的引用替换 threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1); // 更新 threshold， MAXIMUM_CAPACITY的值是 2^30 } put-addEntry-resize-transfertransfer倒是意外的简单，由老table添加到新table，循环遍历，将值插入即可 /** * Transfers all entries from current table to newTable. */ void transfer(Entry[] newTable, boolean rehash) { int newCapacity = newTable.length; for (Entry e : table) { while(null != e) { Entry next = e.next; if (rehash) { e.hash = null == e.key ? 0 : hash(e.key); } int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; } } } put-addEntry-resize-initHashSeedAsNeeded初始化hashSeed还记得那句 We defer initialization until we really need it. 嘛？ 出处来自这里了，switching的取值不是特别明白 /** * Initialize the hashing mask value. We defer initialization until we * really need it. */ final boolean initHashSeedAsNeeded(int capacity) { boolean currentAltHashing = hashSeed != 0; boolean useAltHashing = sun.misc.VM.isBooted() && (capacity >= Holder.ALTERNATIVE_HASHING_THRESHOLD); boolean switching = currentAltHashing ^ useAltHashing; if (switching) { hashSeed = useAltHashing ? sun.misc.Hashing.randomHashSeed(this) : 0; } return switching; } put-addEntry-createEntry最底层的添加元素的方法，是不是简单得亮瞎了眼=。= 唯一能干点活的也就只有Entry的构造函数了，一起看一下 /** * Like addEntry except that this version is used when creating entries * as part of Map construction or \"pseudo-construction\" (cloning, * deserialization). This version needn't worry about resizing the table. * * Subclass overrides this to alter the behavior of HashMap(Map), * clone, and readObject. */ void createEntry(int hash, K key, V value, int bucketIndex) { Entry e = table[bucketIndex]; // 获得当前哈希桶的实例 table[bucketIndex] = new Entry(hash, key, value, e); // 直接new一个Entry，然后替换掉原有的哈系桶，使用链表结构保存原来旧值的实例 // 直接使用哈希桶找到的地一个值，总是最近插入到这个哈希桶的值(有一点时间局部性的意味？) // 具体看Entry的分析 size++; //新添加了一个元素，size加1 } HashMap.EntryEntry是HashMap内部用来存储具体数据的内部类，所有的数据存储在一个Entry&lt;K,V&gt;类型的数组中，看一下Entry的定义 static class Entry implements Map.Entry { final K key; V value; Entry next; int hash; /** * Creates new entry. */ Entry(int h, K k, V v, Entry n) { value = v; next = n; // 这里将原来在这个位置的value保存在了next里面， // 也就是newEntry总是添加在这个哈希桶的链表首部 key = k; hash = h; } public final K getKey() { return key; } public final V getValue() { return value; } public final V setValue(V newValue) { V oldValue = value; value = newValue; return oldValue; } // 为节省篇幅，此处省去了一些关系不大的方法..... } 遍历元素遍历HashMap最快的方法是？ 没错，是EntrySet() 祭出神图先祭出这张神图，有个印象我们再往下看 HashMap |- table HashMap.EntryIterator | \\- next() / 再看代码看一下代码，entrySet()的结构非常简单，有一点需要注意，下面的函数 不是构造函数 /** * Returns a {@link Set} view of the mappings contained in this map. * The set is backed by the map, so changes to the map are * reflected in the set, and vice-versa. If the map is modified * while an iteration over the set is in progress (except through * the iterator's own remove operation, or through the * setValue operation on a map entry returned by the * iterator) the results of the iteration are undefined. The set * supports element removal, which removes the corresponding * mapping from the map, via the Iterator.remove, * Set.remove, removeAll, retainAll and * clear operations. It does not support the * add or addAll operations. * * @return a set view of the mappings contained in this map */ public Set entrySet() { return entrySet0(); } private Set entrySet0() { Set es = entrySet; return es != null ? es : (entrySet = new EntrySet()); } 看上去entrySet保存了一份数据，然后返回的时候直接返回了数据集合，然而这里有一个大坑，实际上EntrySet远远比这牛逼太多了EntrySet是使用iterator来进行遍历，而iterator所调用的内存空间恰好是HashMap保存的table！！！ entrySet其实是table的另外一种展现形式，table改变，entrySet也改变，反之亦然AkaReturns a view of the mappings contained in this map.The set is backed by the map, so changes to the map arereflected in the set, and vice-versa.看不懂没关系，我们慢慢分析 (为了连惯性，以下使用一张长代码块进行展示) /** * EntrySet 类定义 */ private final class EntrySet extends AbstractSet { public Iterator iterator() { return newEntryIterator(); // 这里返回 newEntryInteator，这里是神来之笔 } // 为节省篇幅，省略其他部分方法 } /** * newEntryIterator 是HashMap下的方法 * 做的事情和方法名字一样，new 一个 EntryIterator 对象 */ Iterator newEntryIterator() { return new EntryIterator(); } /** * EntryIterator 是 HashIterator 的子类， * 仅仅重写了next()方法， * 而next方法中调用的nextEntry()，其实也属于 HashIterator */ private final class EntryIterator extends HashIterator { public Map.Entry next() { return nextEntry(); // 是不是有点眼熟? } } /** * HashIterator 是 Iterator 的子类 * 重点看 构造函数 和 nextEntry() 方法 */ private abstract class HashIterator implements Iterator { Entry next; // next entry to return int expectedModCount; // For fast-fail int index; // current slot Entry current; // current entry HashIterator() { expectedModCount = modCount; // 这里对 expectedModCount 赋值，遍历时做校验 if (size > 0) { // advance to first entry /***************************************/ Entry[] t = table; /***************************************/ // 看这里! 看这里! 看这里! // 看这里! 看这里! 看这里! // 看这里! 看这里! 看这里! // t 是 table， 而 table 就是 HashTable 用来存放数据的呀!!!! // 也就是说底层实际上是共用的一套数据！ // 这一行也很有意思， advance to first entry // 移到地一个entry，这里所指向的 entry 和 put 进 map 的顺序没有关系 // index 最终的值为 哈希桶中最小的非空桶的下标 while (index < t.length && (next = t[index++]) == null) ; } } public final boolean hasNext() { return next != null; } /** * nextEntry() * EntryIterator 的 next() 最终调用的方法，也就是迭代器的返回值 * * */ final Entry nextEntry() { // 这里比较了 modCount 和 expectedModCount的取值，如果不同则抛出异常 // expectedModCount 在 HashIterator 的构造器里赋值， 初始值就是 modCount // 而 modCount 在 HashMap 进行元素改变时候会进行 ++ 操作 // 当然这并没什么鸟用，因为完全可以先校验过再同时线程进入竞争区 逃( // if (modCount != expectedModCount) throw new ConcurrentModificationException(); Entry e = next; if (e == null) throw new NoSuchElementException(); // 先看当前哈希桶中是否已经到链表末尾 // 如果是的话就找下一个哈希桶，直到 table 中最后一个哈希桶中的链表的最后一个元素 if ((next = e.next) == null) { Entry[] t = table; while (index < t.length && (next = t[index++]) == null) ; } current = e; return e; } // 为了节省篇幅，减去了一些不必要的代码 } 其他最重要的精华前面已经讲过，还剩下一些其他零散的点， getget方法，本质上调用的getEntry方法，比较简单，不具体介绍了 /** * Returns the value to which the specified key is mapped, * or {@code null} if this map contains no mapping for the key. * * More formally, if this map contains a mapping from a key * {@code k} to a value {@code v} such that {@code (key==null ? k==null : * key.equals(k))}, then this method returns {@code v}; otherwise * it returns {@code null}. (There can be at most one such mapping.) * * A return value of {@code null} does not necessarily * indicate that the map contains no mapping for the key; it's also * possible that the map explicitly maps the key to {@code null}. * The {@link #containsKey containsKey} operation may be used to * distinguish these two cases. * * @see #put(Object, Object) */ public V get(Object key) { if (key == null) return getForNullKey(); Entry entry = getEntry(key); return null == entry ? null : entry.getValue(); } /** * Returns the entry associated with the specified key in the * HashMap. Returns null if the HashMap contains no mapping * for the key. */ final Entry getEntry(Object key) { if (size == 0) { return null; } int hash = (key == null) ? 0 : hash(key); for (Entry e = table[indexFor(hash, table.length)]; e != null; e = e.next) { Object k; if (e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k)))) return e; } return null; } clone克隆方法，注释写得很清楚了Returns a shallow copy，比较危险的方法，不推荐使用 /** * Returns a shallow copy of this HashMap instance: the keys and * values themselves are not cloned. * * @return a shallow copy of this map */ public Object clone() { HashMap result = null; try { result = (HashMap)super.clone(); } catch (CloneNotSupportedException e) { // assert false; } if (result.table != EMPTY_TABLE) { result.inflateTable(Math.min( (int) Math.min( size * Math.min(1 / loadFactor, 4.0f), // we have limits... HashMap.MAXIMUM_CAPACITY), table.length)); } result.entrySet = null; result.modCount = 0; result.size = 0; result.init(); result.putAllForCreate(this); return result; } Another HashMap Constructor注，这里是使用了putAllForCreate，使用了shallow copy，不推荐这样做 /** * Constructs a new HashMap with the same mappings as the * specified Map. The HashMap is created with * default load factor (0.75) and an initial capacity sufficient to * hold the mappings in the specified Map. * * @param m the map whose mappings are to be placed in this map * @throws NullPointerException if the specified map is null */ public HashMap(Map m) { this(Math.max((int) (m.size() / DEFAULT_LOAD_FACTOR) + 1, DEFAULT_INITIAL_CAPACITY), DEFAULT_LOAD_FACTOR); inflateTable(threshold); putAllForCreate(m); } diamond types are not supported at this language level在调试时，把HashMap源码全部复制出来，结果编译不过，告知 diamond types are not supported at this language level void createEntry(int hash, K key, V value, int bucketIndex) { Entry e = table[bucketIndex]; table[bucketIndex] = new Entry(hash, key, value, e); // 就是这一行 // ↑↑↑↑ // here // size++; } 经过搜索，发现其实是项目所使用的是language level 6，如下图所示进行修改即可 mystical transient?在复制源码的时候，发现在全选的情况下，一下两行没有被复制过来，难道这和transient有关系？？？但是同样被transient修饰的entrySet却被复制了过来，明明都是Ctrl-C Ctrl-V为啥有区别嘞 =。= transient volatile Set keySet = null; // 我没有被复制哦 transient volatile Collection values = null; // 我没有被复制哦 private transient Set entrySet = null; // 我被复制了哦 小结HashMap是一个很强大的集合类，小结一下: 其中使用Hash函数进行较快的检索，在hash冲突时使用链表进行数据的存储 当内部空间不足时，会自动进行扩容，扩容长度为原来的2倍，并且会将旧的数据全部映射到新数据上，当HashMap长度较大时，再进行扩展开销会比较大 遍历HashMap时，最好使用EntrySet()进行遍历，使用的时候注意方法The set supports element removal, which removes the corresponding mapping from the map,via the Iterator.remove, Set.remove, removeAll, retainAll and clear operations.It does not support the add or addAll operations.","categories":[{"name":"Java","slug":"Java","permalink":"http://kevingeek.github.io/categories/Java/"}],"tags":[{"name":"Collection","slug":"Collection","permalink":"http://kevingeek.github.io/tags/Collection/"}]},{"title":"MarkDown 写法乱弹","slug":"MarkDown","date":"2016-07-25T13:17:17.000Z","updated":"2020-04-09T04:19:33.057Z","comments":true,"path":"2016/07/25/MarkDown/","link":"","permalink":"http://kevingeek.github.io/2016/07/25/MarkDown/","excerpt":"这是超链接备忘全在这上面MarkDown语法","text":"这是超链接备忘全在这上面MarkDown语法 This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisseid sem consectetuer libero luctus adipiscing. 标题哦 This is an H1This is an H2第一次来这边写日志，算是第一篇真正意义上的个人blog日志，好的开始，Hello World！ Use the printf() function. 以下是Java代码 System.out.println(\"hello world!\"); 这是很重要的 line_number line_two 恩，这是星号 恩，这是加号 分割符 第一点 第二点","categories":[{"name":"feel","slug":"feel","permalink":"http://kevingeek.github.io/categories/feel/"}],"tags":[{"name":"First","slug":"First","permalink":"http://kevingeek.github.io/tags/First/"},{"name":"Second","slug":"Second","permalink":"http://kevingeek.github.io/tags/Second/"}]}]}